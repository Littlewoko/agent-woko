{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc729cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "\n",
    "dbuser = os.getenv(\"PGUSER\")\n",
    "dbpassword = os.getenv(\"PGPASSWORD\")\n",
    "dbhost = os.getenv(\"PGHOST\")\n",
    "dbname = os.getenv(\"PGDATABASE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(f\"dbname={dbname} user={dbuser} host={dbhost} password={dbpassword}\") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM books LIMIT 10\")\n",
    "        print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_books():\n",
    "    with psycopg.connect(f\"dbname={dbname} user={dbuser} host={dbhost} password={dbpassword}\") as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT (title, author, genre, datecompleted, datestartedreading, shortstory) FROM books\")\n",
    "            return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ai_prompt_from_books(books_data: list[tuple]) -> str:\n",
    "    \"\"\"\n",
    "    Transforms a list of book data tuples into a well-structured, human-readable\n",
    "    string suitable for an AI model's context.\n",
    "\n",
    "    Args:\n",
    "        books_data: A list of tuples, where each tuple contains book information\n",
    "                    in the order: (title, author, genre, datecompleted, datestartedreading, shortstory).\n",
    "\n",
    "    Returns:\n",
    "        A formatted string containing all the book data, with each book\n",
    "        separated by a clear delimiter.\n",
    "    \"\"\"\n",
    "    # A list to hold the formatted strings for each book\n",
    "    formatted_books = []\n",
    "\n",
    "    # Iterate through the list of book tuples\n",
    "    for book_outer_tuple in books_data:\n",
    "        book = book_outer_tuple[0]\n",
    "\n",
    "        # Unpack the tuple for easier access to each field\n",
    "        title, author, genre, datecompleted, datestartedreading, shortstory = book\n",
    "\n",
    "        # Format the information for a single book.\n",
    "        # We use a f-string for easy readability and variable insertion.\n",
    "        # The formatting is designed to be clear and consistent for the AI.\n",
    "        book_string = (\n",
    "            f\"Title: {title}\\n\"\n",
    "            f\"Author: {author}\\n\"\n",
    "            f\"Genre: {genre}\\n\"\n",
    "            f\"Date Started Reading: {datestartedreading}\\n\"\n",
    "            f\"Date Completed: {datecompleted}\\n\"\n",
    "            f\"Is a Short Story: {'No' if shortstory == 'f' else 'Yes'}\\n\"\n",
    "        )\n",
    "        formatted_books.append(book_string)\n",
    "\n",
    "    # Join all the formatted book strings together with a separator\n",
    "    # to make each book a distinct block of information.\n",
    "    # The final string is then returned.\n",
    "    return \"\\n\" + \"---\" * 15 + \"\\n\".join(formatted_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e43ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "# 1. First, you would call your get_books() function to fetch the data.\n",
    "# For this example, we'll use the mock data function.\n",
    "books_from_db = get_books()\n",
    "\n",
    "# 2. Then, pass the fetched data to the function to create the prompt string.\n",
    "ai_context_prompt = create_ai_prompt_from_books(books_from_db)\n",
    "\n",
    "# 3. Print the final prompt to see the result.\n",
    "# This is the string you would then pass to your AI model.\n",
    "# print(ai_context_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are a helpful assistant that can answer questions about books.\n",
    "    You are given a list of books and their details.\n",
    "    You can use this information to answer questions about the books.\n",
    "    You can also use this information to answer questions about the user's reading habits.\n",
    "    You can also use this information to answer questions about the user's reading preferences.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character.\"\n",
    "\n",
    "system_prompt += f\"\\n{ai_context_prompt}\"\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
