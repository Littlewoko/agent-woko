{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc729cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "\n",
    "dbuser = os.getenv(\"PGUSER\")\n",
    "dbpassword = os.getenv(\"PGPASSWORD\")\n",
    "dbhost = os.getenv(\"PGHOST\")\n",
    "dbname = os.getenv(\"PGDATABASE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(f\"dbname={dbname} user={dbuser} host={dbhost} password={dbpassword}\") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM books LIMIT 10\")\n",
    "        print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_books():\n",
    "    with psycopg.connect(f\"dbname={dbname} user={dbuser} host={dbhost} password={dbpassword}\") as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT (title, author, genre, datecompleted, datestartedreading, shortstory) FROM books\")\n",
    "            return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "    with psycopg.connect(f\"dbname={dbname} user={dbuser} host={dbhost} password={dbpassword}\") as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "            WITH counts AS (\n",
    "                SELECT \n",
    "                    COUNT(id) FILTER (WHERE datestartedreading IS NOT NULL AND datecompleted IS NULL) AS inProgress,\n",
    "                    COUNT(id) FILTER (WHERE datecompleted IS NOT NULL AND shortstory = false) AS completedCount,\n",
    "                    COUNT(id) FILTER (WHERE datecompleted IS NOT NULL AND shortstory = true) AS shortstorycount,\n",
    "                    COUNT(id) FILTER (WHERE datecompleted IS NOT NULL AND EXTRACT(YEAR FROM datecompleted) = EXTRACT(YEAR FROM CURRENT_DATE) AND shortstory = false) AS completedthisyearcount,\n",
    "                    COUNT(id) FILTER (WHERE datecompleted IS NOT NULL AND EXTRACT(YEAR FROM datecompleted) = EXTRACT(YEAR FROM CURRENT_DATE) AND shortstory = true) AS shortstorythisyearcount\n",
    "                FROM books\n",
    "            )\n",
    "            SELECT *\n",
    "            FROM counts;\n",
    "            \"\"\")\n",
    "            stats_data = cur.fetchall()\n",
    "\n",
    "            \"\"\"\n",
    "            Transforms the reading statistics tuple into a well-structured,\n",
    "            human-readable string suitable for an AI model's context.\n",
    "\n",
    "            Args:\n",
    "                stats_data: A list containing a single tuple with reading statistics.\n",
    "                            The tuple format is:\n",
    "                            (inProgress, completedCount, shortstorycount, completedthisyearcount, shortstorythisyearcount)\n",
    "\n",
    "            Returns:\n",
    "                A formatted string containing the user's reading statistics.\n",
    "            \"\"\"\n",
    "            # Check if the list is not empty and contains a tuple\n",
    "            if not stats_data or not isinstance(stats_data[0], tuple):\n",
    "                return \"No reading statistics available.\"\n",
    "\n",
    "            # Unpack the single tuple for easier access to each statistic\n",
    "            stats = stats_data[0]\n",
    "            (inProgress, completedCount, shortstorycount, completedthisyearcount, shortstorythisyearcount) = stats\n",
    "\n",
    "            # Format the information into a clear string.\n",
    "            # The labels are designed to be easily understood by an AI.\n",
    "            stats_string = (\n",
    "                f\"--- Reading Statistics ---\\n\"\n",
    "                f\"Books currently in progress: {inProgress}\\n\"\n",
    "                f\"Total books completed: {completedCount}\\n\"\n",
    "                f\"Total short stories completed: {shortstorycount}\\n\"\n",
    "                f\"Books completed this year: {completedthisyearcount}\\n\"\n",
    "                f\"Short stories completed this year: {shortstorythisyearcount}\\n\"\n",
    "                f\"--------------------------\\n\"\n",
    "            )\n",
    "            return stats_string\n",
    "\n",
    "get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ai_prompt_from_stats(stats_data: list[tuple]) -> str:\n",
    "    \"\"\"\n",
    "    Transforms the reading statistics tuple into a well-structured,\n",
    "    human-readable string suitable for an AI model's context.\n",
    "\n",
    "    Args:\n",
    "        stats_data: A list containing a single tuple with reading statistics.\n",
    "                    The tuple format is:\n",
    "                    (inProgress, completedCount, shortstorycount, completedthisyearcount, shortstorythisyearcount)\n",
    "\n",
    "    Returns:\n",
    "        A formatted string containing the user's reading statistics.\n",
    "    \"\"\"\n",
    "    # Check if the list is not empty and contains a tuple\n",
    "    if not stats_data or not isinstance(stats_data[0], tuple):\n",
    "        return \"No reading statistics available.\"\n",
    "\n",
    "    # Unpack the single tuple for easier access to each statistic\n",
    "    stats = stats_data[0]\n",
    "    (inProgress, completedCount, shortstorycount, completedthisyearcount, shortstorythisyearcount) = stats\n",
    "\n",
    "    # Format the information into a clear string.\n",
    "    # The labels are designed to be easily understood by an AI.\n",
    "    stats_string = (\n",
    "        f\"--- Reading Statistics ---\\n\"\n",
    "        f\"Books currently in progress: {inProgress}\\n\"\n",
    "        f\"Total books completed: {completedCount}\\n\"\n",
    "        f\"Total short stories completed: {shortstorycount}\\n\"\n",
    "        f\"Books completed this year: {completedthisyearcount}\\n\"\n",
    "        f\"Short stories completed this year: {shortstorythisyearcount}\\n\"\n",
    "        f\"--------------------------\\n\"\n",
    "    )\n",
    "    return stats_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"name\": \"get_stats\",\n",
    "    \"description\": \"Retrieves the user's reading statistics, including books in progress, total completed, and counts for the current year.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {},\n",
    "        \"required\": [],\n",
    "        \"additionalProperties\": false\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ai_prompt_from_books(books_data: list[tuple]) -> str:\n",
    "    \"\"\"\n",
    "    Transforms a list of book data tuples into a well-structured, human-readable\n",
    "    string suitable for an AI model's context.\n",
    "\n",
    "    Args:\n",
    "        books_data: A list of tuples, where each tuple contains book information\n",
    "                    in the order: (title, author, genre, datecompleted, datestartedreading, shortstory).\n",
    "\n",
    "    Returns:\n",
    "        A formatted string containing all the book data, with each book\n",
    "        separated by a clear delimiter.\n",
    "    \"\"\"\n",
    "    # A list to hold the formatted strings for each book\n",
    "    formatted_books = []\n",
    "\n",
    "    # Iterate through the list of book tuples\n",
    "    for book_outer_tuple in books_data:\n",
    "        book = book_outer_tuple[0]\n",
    "\n",
    "        # Unpack the tuple for easier access to each field\n",
    "        title, author, genre, datecompleted, datestartedreading, shortstory = book\n",
    "\n",
    "        # Format the information for a single book.\n",
    "        # We use a f-string for easy readability and variable insertion.\n",
    "        # The formatting is designed to be clear and consistent for the AI.\n",
    "        book_string = (\n",
    "            f\"Title: {title}\\n\"\n",
    "            f\"Author: {author}\\n\"\n",
    "            f\"Genre: {genre}\\n\"\n",
    "            f\"Date Started Reading: {datestartedreading}\\n\"\n",
    "            f\"Date Completed: {datecompleted}\\n\"\n",
    "            f\"Is a Short Story: {'No' if shortstory == 'f' else 'Yes'}\\n\"\n",
    "        )\n",
    "        formatted_books.append(book_string)\n",
    "\n",
    "    # Join all the formatted book strings together with a separator\n",
    "    # to make each book a distinct block of information.\n",
    "    # The final string is then returned.\n",
    "    return \"\\n\" + \"---\" * 15 + \"\\n\".join(formatted_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e43ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "# 1. First, you would call your get_books() function to fetch the data.\n",
    "# For this example, we'll use the mock data function.\n",
    "# books_from_db = get_books()\n",
    "\n",
    "# 2. Then, pass the fetched data to the function to create the prompt string.\n",
    "# ai_context_prompt = create_ai_prompt_from_books(books_from_db)\n",
    "\n",
    "# 3. Print the final prompt to see the result.\n",
    "# This is the string you would then pass to your AI model.\n",
    "# print(ai_context_prompt)\n",
    "\n",
    "stats = get_stats()\n",
    "\n",
    "ai_stats_context = create_ai_prompt_from_stats(stats)\n",
    "print(ai_stats_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are a helpful assistant that can answer questions about books.\n",
    "    You are given a list of books and their details.\n",
    "    You can use this information to answer questions about the books.\n",
    "    You can also use this information to answer questions about the user's reading habits.\n",
    "    You can also use this information to answer questions about the user's reading preferences.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character.\"\n",
    "\n",
    "system_prompt += f\"\\n{ai_context_prompt}\"\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
